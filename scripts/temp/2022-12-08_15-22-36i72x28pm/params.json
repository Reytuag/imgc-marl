{
  "_disable_action_flattening": false,
  "_disable_execution_plan_api": true,
  "_disable_preprocessor_api": false,
  "_fake_gpus": false,
  "_tf_policy_handles_more_than_one_loss": false,
  "action_space": null,
  "actions_in_input_normalized": false,
  "always_attach_evaluation_results": false,
  "batch_mode": "truncate_episodes",
  "callbacks": "<class 'imgc_marl.callbacks.PopGoalLinesCallback'>",
  "clip_actions": false,
  "clip_param": 0.3,
  "clip_rewards": null,
  "collect_metrics_timeout": -1,
  "compress_observations": false,
  "create_env_on_driver": false,
  "custom_eval_function": "<function custom_eval_function at 0x7fc1f5f50200>",
  "custom_resources_per_worker": {},
  "disable_env_checking": false,
  "eager_max_retraces": 20,
  "eager_tracing": false,
  "entropy_coeff": 0.0,
  "entropy_coeff_schedule": null,
  "env": null,
  "env_config": {
    "all_goals": true,
    "centralized": false,
    "new_reward": true,
    "population_size": 2,
    "reward_multiplier": 2
  },
  "env_task_fn": null,
  "evaluation_config": {
    "eval_goals": [
      {
        "agent_0": 0,
        "agent_1": 0
      },
      {
        "agent_0": 1,
        "agent_1": 1
      },
      {
        "agent_0": 2,
        "agent_1": 2
      },
      {
        "agent_0": 3,
        "agent_1": 3
      },
      {
        "agent_0": 4,
        "agent_1": 4
      },
      {
        "agent_0": 5,
        "agent_1": 5
      },
      {
        "agent_0": 6,
        "agent_1": 6
      },
      {
        "agent_0": 7,
        "agent_1": 7
      },
      {
        "agent_0": 8,
        "agent_1": 8
      },
      {
        "agent_0": 9,
        "agent_1": 9
      },
      {
        "agent_0": 10,
        "agent_1": 10
      },
      {
        "agent_0": 11,
        "agent_1": 11
      },
      {
        "agent_0": 12,
        "agent_1": 12
      },
      {
        "agent_0": 13,
        "agent_1": 13
      },
      {
        "agent_0": 14,
        "agent_1": 14
      },
      {
        "agent_0": 15,
        "agent_1": 15
      },
      {
        "agent_0": 16,
        "agent_1": 16
      },
      {
        "agent_0": 17,
        "agent_1": 17
      },
      {
        "agent_0": 18,
        "agent_1": 18
      },
      {
        "agent_0": 19,
        "agent_1": 19
      },
      {
        "agent_0": 20,
        "agent_1": 20
      }
    ]
  },
  "evaluation_duration": 10,
  "evaluation_duration_unit": "episodes",
  "evaluation_interval": 10,
  "evaluation_num_episodes": -1,
  "evaluation_num_workers": 2,
  "evaluation_parallel_to_training": false,
  "exploration_config": {
    "type": "StochasticSampling"
  },
  "explore": true,
  "extra_python_environs_for_driver": {},
  "extra_python_environs_for_worker": {},
  "fake_sampler": false,
  "framework": "torch",
  "gamma": 0.99,
  "grad_clip": null,
  "horizon": 500,
  "ignore_worker_failures": false,
  "in_evaluation": false,
  "input": "sampler",
  "input_config": {},
  "input_evaluation": [
    "is",
    "wis"
  ],
  "keep_per_episode_custom_metrics": false,
  "kl_coeff": 0.2,
  "kl_target": 0.01,
  "lambda": 0.9,
  "local_tf_session_args": {
    "inter_op_parallelism_threads": 8,
    "intra_op_parallelism_threads": 8
  },
  "log_level": "WARN",
  "log_sys_usage": true,
  "logger_config": null,
  "lr": 0.0003,
  "lr_schedule": null,
  "metrics_episode_collection_timeout_s": 180,
  "metrics_num_episodes_for_smoothing": 100,
  "metrics_smoothing_episodes": -1,
  "min_iter_time_s": -1,
  "min_sample_timesteps_per_reporting": null,
  "min_time_s_per_reporting": null,
  "min_train_timesteps_per_reporting": null,
  "model": {
    "custom_model": "cc_model"
  },
  "monitor": -1,
  "multiagent": {
    "policies": {
      "agent_0": [
        null,
        null,
        null,
        null
      ],
      "agent_1": [
        null,
        null,
        null,
        null
      ]
    },
    "policy_mapping_fn": "<function train.<locals>.policy_mapping_fn at 0x7fc1f5cdc8c0>"
  },
  "no_done_at_end": false,
  "normalize_actions": true,
  "num_cpus_for_driver": 1,
  "num_cpus_per_worker": 1,
  "num_envs_per_worker": 1,
  "num_gpus": 0,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 30,
  "num_workers": 2,
  "observation_filter": "NoFilter",
  "observation_space": null,
  "optimizer": {},
  "output": null,
  "output_compress_columns": [
    "obs",
    "new_obs"
  ],
  "output_config": {},
  "output_max_file_size": 67108864,
  "placement_strategy": "PACK",
  "postprocess_inputs": false,
  "preprocessor_pref": "deepmind",
  "record_env": false,
  "recreate_failed_workers": false,
  "remote_env_batch_wait_ms": 0,
  "remote_worker_envs": false,
  "render_env": false,
  "rollout_fragment_length": 500,
  "sample_async": false,
  "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
  "seed": 769132,
  "sgd_minibatch_size": 10000,
  "shuffle_buffer_size": 0,
  "shuffle_sequences": true,
  "simple_optimizer": -1,
  "soft_horizon": false,
  "synchronize_filters": true,
  "tf_session_args": {
    "allow_soft_placement": true,
    "device_count": {
      "CPU": 1
    },
    "gpu_options": {
      "allow_growth": true
    },
    "inter_op_parallelism_threads": 2,
    "intra_op_parallelism_threads": 2,
    "log_device_placement": false
  },
  "timesteps_per_iteration": 0,
  "train_batch_size": 60000,
  "use_critic": true,
  "use_gae": true,
  "vf_clip_param": 10.0,
  "vf_loss_coeff": 1.0
}